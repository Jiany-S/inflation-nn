# ğŸ“ˆ Inflation Nowcasting with LSTM

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

This project implements a **deep learning pipeline for inflation nowcasting** using Long Short-Term Memory (LSTM) networks.  
It leverages macroeconomic data to forecast near-term inflation trends and benchmark them against classical baselines.

---

## ğŸ“‚ Repository Structure

```bash
.
â”œâ”€â”€ app/                  # (optional) Deployment app (Streamlit, FastAPI, etc.)
â”œâ”€â”€ notebooks/            # Jupyter notebooks for experiments & EDA
â”œâ”€â”€ results/              # Generated plots & metrics
â”‚   â”œâ”€â”€ backtest_metrics.json
â”‚   â”œâ”€â”€ baselines.json
â”‚   â”œâ”€â”€ coverage.txt
â”‚   â”œâ”€â”€ feature_importance.json / .png
â”‚   â”œâ”€â”€ learning_curves.png
â”‚   â”œâ”€â”€ metrics.json
â”‚   â”œâ”€â”€ preds_vs_actuals.png
â”œâ”€â”€ saved_models/         # Trained models & scalers
â”‚   â”œâ”€â”€ inflation_model.keras
â”‚   â””â”€â”€ scaler.pkl
â”œâ”€â”€ src/                  # Core source code
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ data.py
â”‚   â”œâ”€â”€ forecast.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ visualize.py
â”œâ”€â”€ tests/                # Unit tests
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Installation

```bash
git clone https://github.com/<your-username>/inflation-nowcast.git
cd inflation-nowcast
pip install -r requirements.txt
```

---

## ğŸ§  Training

```bash
python -m src.train
```

This will:  
- Load & preprocess data from FRED  
- Train the LSTM model  
- Save plots & metrics under `results/`  
- Save trained model & scaler under `saved_models/`

---

## ğŸ“Š Results

Key artifacts under `results/`:

- **Learning Curves** â€“ training/validation MSE (`learning_curves.png`)  
- **Predictions vs Actuals** â€“ alignment on test set (`preds_vs_actuals.png`)  
- **Feature Importance** â€“ permutation importances (`feature_importance.png`, `feature_importance.json`)  
- **Backtest Metrics** (`backtest_metrics.json`) â€“ fold-by-fold MAE/MSE vs baseline  
- **Baselines** (`baselines.json`) â€“ naive, seasonal naive, ARIMA baselines  
- **Coverage** (`coverage.txt`) â€“ empirical coverage of MC dropout bands  
- **Final Metrics** (`metrics.json`) â€“ final MAE/MSE on test set

Example visualizations:

![Learning Curves](results/learning_curves.png)  
![Preds vs Actuals](results/preds_vs_actuals.png)  
![Feature Importance](results/feature_importance.png)

---

## ğŸ“Œ Baseline Comparison

- Naive last value MAE: ~0.31  
- Seasonal naive MAE: ~0.35  
- ARIMA(1,0,0) MAE: ~0.30  
- LSTM folds: MAE ~0.17â€“0.30 (better than naive in most folds)  
- Final test MAE: ~0.40

---

## ğŸ— Model Architecture

- Input: macro features over last `N_LAGS` months  
- Model: stacked LSTM with dropout regularization  
- Output: next monthâ€™s inflation forecast

---

## ğŸš€ Future Work

- Improve uncertainty calibration (current 80% band â‰ˆ 32% empirical coverage)  
- Hyperparameter tuning with Optuna  
- Richer exogenous features (oil, FX, sentiment indices)  
- Interactive dashboards (Streamlit / Plotly)

---

ğŸ‘¨â€ğŸ’» Author: **[Jiany Samara](https://github.com/Jiany-S)**
